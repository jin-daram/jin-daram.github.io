{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"기존 운영 서비스에서 업로드 된 파일명을 WHERE 조건을 걸어 조회 해야하는 일이 생겼다.\n테스트 목적으로 로컬에서 파일을 업로드 하고 조건절에 파일 명을 걸어, SQL을 날렸는데 분명 동일한 파일 제목인데도 불구하고 조회 결과에 포함되지 않는 문제가 생겼다. 그러던 중 DB 컬럼 값을 자세히 살펴보니 다음과 같은 기이한 현상이 발생하였다. 비정상적인 …","fields":{"slug":"/nfd-nfc/"},"frontmatter":{"date":"July 08, 2025","title":"문자열이 자소분리가 되어 DB 저장되는 이슈 해결","tags":["이슈","NFD/NFC","인코딩"]},"rawMarkdownBody":"\n기존 운영 서비스에서 업로드 된 파일명을 WHERE 조건을 걸어 조회 해야하는 일이 생겼다.<br>\n테스트 목적으로 로컬에서 파일을 업로드 하고 조건절에 파일 명을 걸어, SQL을 날렸는데 분명 동일한 파일 제목인데도 불구하고 조회 결과에 포함되지 않는 문제가 생겼다.<br>\n\n그러던 중 DB 컬럼 값을 자세히 살펴보니 다음과 같은 기이한 현상이 발생하였다.<br><br>\n\n![비정상적인 상황](./1.gif)\n\n![정상적인 상황](./2.gif)\n<br>\n정리하자면, 파일명이 자소분리가 된 형태로 DB에 저장되는 아주 당황스러운 상황이 발생했다.\n\n## 원인 분석\n---\nNaver OCR의 추정값이 원인인지, DB 인코딩이 원인인지, 처음엔 원인을 몰라서 헤매다가, 여러 가지 상황에서 테스트를 해봤다. \n\n**기존에 발생한 버그인가?**\n\n기존에는 발생했어도 방법을 찾을 수가 없었다. 저 컬럼의 이름은 originalName 이라는 컬럼인데, 해당 값은 그냥 저장 할 뿐 비즈니스 로직에서 사용하지는 않았다. 그래서 기존에 어떤 형식으로 저장되는지 확인할 수 없었다.\n\n현상이 최초 발생한 경로는 로컬에서 띄운 Spring Boot의 Swagger API Docs에 접근해서 API를 날린 상태이다. 그 후 개발 서버에 접근해서 클라이언트를 통해 API를 요청했다. \n\n로컬 서버 버전에서 문제가 생기거나, 로컬 환경과 밀접하여 문제가 생긴 것으로 판단했지만, 개발 서버 클라이언트를 통해 API를 날렸을 때, 동일한 문제가 발생하여 서버의 문제는 아닌 것으로 판단되었다. \n\n그런 후 브라우저에 관한 문제인가 싶어서, **Safari를 통해 업로드 해봤다.** 그러자 정상적으로 DB에 데이터가 올라간 것을 확인할 수 있었다.\n\n## Safari에선 정상적으로 업로드가 이루어지는 기이한 현상\n---\n\n여러 원인을 찾아보던 도중, NFC와 NFD 에 대해 알게 되었고, 이것과 밀접한 관련이 있음을 깨닫게 되었다.\n\n### NFC와 NFD\n---\n\nMac 사용자들이라면 가끔 파일 이름이 다음과 같이 저장된 것을 본 경험이 있을 것이다.\n\n```text\nㅇㅣㄱㅓㅅㅇㅡㄴ ㅇㅣㄹㅂㅏㄴ ㅁㅜㄴㅅㅓㅇㅣㅁ.txt\n```\n\n원래라면 다음과 같은 제목인데 말이다.\n\n```text\n이것은 일반 문서임.txt\n```\n\n이러한 차이를 알기 위해서 **NFD (Normalize From Decomposed**) 과 **NFC(Normalize From Composed)** 에 대해서 알아두어야 한다.\n\n### NFC (Normalize From Composed)\n---\n사람이 보는 글자와 같다. 즉 하나의 문자로 합쳐진 형태이다.\n`가` 라는 문자가 있을 때, 이를 `U+AC00` 으로 표현한다.\n\n### NFD (Normalization Form Decomposed)\n---\n하나의 글자를 초성/중성/종성 등으로 분리한 형태이다.\n`가` 라는 문자가 있을 때, 이를 `ㄱ` + `ㅏ` 로 분리하여 정규화한다.\n\nMac OS 에서 한글로 이루어진 파일명을 저장했을 때, 자소 분리가 되어 저장된 것은 Mac OS 에서 기본적으로 NFD 유니코드 정규화 방식을 사용하기 때문이다.\n\n> [!NOTE]\n> Windows 운영체제는 기본적으로 NFD 유니코드 정규화 방식을 사용한다고 한다.\n> [참조 문서](https://learn.microsoft.com/en-us/windows/win32/intl/using-unicode-normalization-to-represent-strings)\n\n### MacOS + Safari / MacOS + Chrome\n---\n본론으로 돌아와서, MacOS 에서 기본적으로 NFD 정규화 방식을 사용하는 것을 알게 되었다. 다만 Safari로 업로드를 진행 했을 땐, 왜 정상적으로 DB에 값이 저장되는 것일까?\n\n그 이유는 Safari 에서는 모든 POST 요청을 NFC 방식으로 인코딩하여 보내기 때문이다. \n\n[https://bugs.webkit.org/show_bug.cgi?id=30387](https://bugs.webkit.org/show_bug.cgi?id=30387&utm_source=chatgpt.com)\n\n해당 글에서 명시적으로 Safari가 `NFC normalization` 으로 요청을 보낸다고 한다. 그렇기 때문에 NFD 기반의 Mac OS에서도 우리가 원하는 형태인 `ㄱㅏ` 가 아닌 `가` 의 형태로 데이터를 받을 수 있는 것이다.\n\n반면 Chrome은 OS의 유니코드 정규화 방식을 따르기 떄문에 Chrome으로 파일을 업로드 할 경우 DB에 Mac OS의 유니코드 정규화 방식은 NFD 문자열로 데이터가 저장되는 것이다.\n\n## 해결 방법\n---\n문제의 원인을 찾았으니, 해결 방법을 알아봤다. 광징히 간단하게 해결할 수 있었다.\njava.text 에 존재하는  Normalization을 지원하는 라이브러리가 존재하여 해당 Normalizer에 normalize 함수를 통해 NFC 형태로 유니코드 정규화를 처리할 수 있었다.\n\n```java\nString input = \"...\"; // NFD 기반 문자열\nString nfc = Normalizer.normalize(input, Normalizer.Form.NFC);\n```\n\n적용한 후 Chrome을 통해 데이터를 업로드하니 NFC 정규화 상태로 저장된 것을 확인할 수 있다."},{"excerpt":"네이버에서 가장 많이 방문하는 주소는 뭘까요?  보통 https://naver.com 으로 접속하는 경우가 가장 많습니다. 그렇기 때문에 메인 페이지 접속 시 호출되는 API가 느리다면 사용자 경험에 큰 영향을 줄 수밖에 없습니다. 실무에서 개발한 서비스도 메인 페이지에서 여러 API를 호출하고 있었고, 단순 캐싱 수준을 넘어 쿼리 플랜에 대한 분석을 통…","fields":{"slug":"/query-plan-analysis/"},"frontmatter":{"date":"June 17, 2025","title":"실무에서 쿼리 플랜을 통한 성능 개선 경험 (feat. 134배 향상)","tags":["성능개선","쿼리플랜","실무"]},"rawMarkdownBody":"[네이버](https://naver.com)에서 가장 많이 방문하는 주소는 뭘까요? \n\n[보통 https://naver.com 으로 접속하는 경우가 가장 많습니다.](https://www.semrush.com/website/top/south-korea/all/) 그렇기 때문에 메인 페이지 접속 시 호출되는 API가 느리다면 사용자 경험에 큰 영향을 줄 수밖에 없습니다.\n\n실무에서 개발한 서비스도 메인 페이지에서 여러 API를 호출하고 있었고, 단순 캐싱 수준을 넘어 쿼리 플랜에 대한 분석을 통해 개선한 경험을 소개드리려고 합니다. \n\n## 피드 API 개선\n---\n성능을 실질적으로 개선하기 전에 문제의 원인을 분석해볼 수 있는 방법 중 하나가 데이터베이스로 전달되는 쿼리를 분석하는 것 입니다. 데이터베이스로 전달된 쿼리가 옵티마이저에 의해 어떤 실행 계획을 가지고 데이터를 찾았는지 알게 된다면 쿼리 개선에 도움이 될 수 있습니다. \n\n*(쿼리를 보기 좋게 다듬은 결과이며, Spring Boot 기준 Hibernate 에 의해 생성된 쿼리가 전송되기 때문에 아래 쿼리 플랜과 비교하여 Alias 와 같은 차이점은 있으나, 구조는 동일합니다.)*\n\n```sql\nSELECT a.id\nFROM article a\n\tLEFT OUTER JOIN article_tag tag1 ON a.id = tag1.article_id\n\tLEFT OUTER JOIN article_tag tag2 ON tag1.tag_id = tag2.id\nWHERE ( a.user_id = ? OR tag2.id = ? )\n\tAND ( a.category_id IN ( ?, ?) )\n\tAND a.is_deleted = ?\n\tAND a.is_block = ?\nGROUP BY a.id\nORDER BY a.id DESC\n```\n\n위 쿼리는 병목이 발생한다고 여겨지는 쿼리입니다. 해당 쿼리를 분석하기 위해 `PostgreSQL` 기준 `EXPLAIN ANALYZE` 구문을 추가해주도록 합니다.\n\n```sql\nEXPLAIN ANALYZE\nSELECT a.id\nFROM article a\n\tLEFT OUTER JOIN article_tag tag1 ON a.id = tag1.article_id\n\tLEFT OUTER JOIN article_tag tag2 ON tag1.tag_id = tag2.id\nWHERE ( a.user_id = ? OR tag2.id = ? )\n\tAND ( a.category_id IN ( ?, ?) )\n\tAND a.is_deleted = ?\n\tAND a.is_block = ?\nGROUP BY a.id\nORDER BY a.id DESC\n```\n\n\n![](query-plan-result.png)\n\n처음 본다면 다소 당황스러울 수 있습니다. 그래서 가장 먼저 읽는 순서를 알아야 합니다. 그래야 어떤 방식으로 데이터를 조회하는지에 대한 쿼리 실헹 계획을 알아갈 수 있습니다. 실행 계획이 조금 길기 때문에 여러 구역으로 분리해서 알아보도록 합니다.\n\n![](./divide-query-result.png)\n\n### 초록색 구역\n---\n가장 먼저 `초록색 구간`에 대해 알아보는 이유는 보통 위에서 아래로 절차적으로 실행되는 것이라고 생각할 수 있겠지만 쿼리 플랜은 그렇지 않습니다. 각각의 작업들은 일련의 계층 구조를 가지며 부분적으로 절차적으로 진행됩니다. \n\n그 말은 즉, 어떠한 계층이 여러 하위 계층들을 가진다면 그 하위 계층들은 순차적으로 실행된다는 의미입니다. 각각의 계층은 화살표 (→) 로 구분되는데, `파란색 계층` 아래에는 2개의 계층이 존재합니다.\n\n![](./blue-has-two-depth.png)\n\n `Seq Scan on article article0_` 로 시작하는 작업은 첫 번째 하위 계층이기 때문에 가장 먼저 실행됩니다. \n 작업이 끝나면 다음 하위 계층인 `Seq Scan on article_tag tags1_` 작업이 실행됩니다.\n\n이제 번호를 통해 어떤 순서로 시작하는 지 감을 잡아보도록 하겠습니다.\n\n![](./query-plan-sequence.png)\n\n1. `Filter` 를 보면 조건절이 있습니다. Article 테이블을 `Seq Scan (Full Scan)` 하여 해당 조건에 적합한 `article` 데이터를 조회합니다.\n2. `LEFT JOIN` 을 위해 article_tag 테이블의 데이터를 스캔합니다.\n3. `LEFT JOIN` 을 위해 tag 테이블의 데이터를 스캔합니다.\n4. `JOIN` 을 위해 `Hash Table` 을 생성합니다.\n5. `article_tag` 테이블과 `tag` 테이블을 조인합니다.\n6. `JOIN` 을 하기 위한 `Hash Table` 을 생성합니다.\n\n### 파란색 구역\n---\n\n![](./blue-section.png)\n\n이제까지 기본적인 조건과 적합한 `article` 데이터를 조회했고, `article_tag` 테이블과 `tag` 테이블을 `JOIN` 한 `Hash Table` 을 생성했습니다. 그리고 `파란색 구역` 은 JOIN을 하게 되는 구간입니다.\n\n그 과정에서 \n`article.user_id = ? OR tag.id = ?` \n조건절을 만족하는 레코드를 필터링 하게 됩니다. 이 과정을 `파란색 구역`에서 수행하게 됩니다.\n\n### 빨간색 구간\n---\n\n![](./red-section.png)\n\n빨간색 구간은 그 이후에 있는 `ORDER BY`, `GROUP BY` 를 수행하게 됩니다. \n\n### 성능 추적\n---\n이제까지 유저 피드 조회 시에 실행되는 쿼리에 대해 분석해봤습니다. 이제 쿼리를 실행하게 되면 실제로 어떤 순서와 방법으로 데이터를 조회하는지 간략하게나마 알게되었고, 마지막에는 현재 테이블의 데이터를 기준으로 실행되는 쿼리의 시간을 알 수 있습니다. \n\n![실제 쿼리 실행 시간은 Execution Time: 67.285ms](./query-execution-time.png)\n\n다만 우리가 궁금한 건 어떤 순서로 작업을 진행하는지가 아닙니다. 최종적으로 생성된 쿼리가 얼마나 효율적으로 높은 성능으로 데이터를 조회해오는지이고, 그렇지 못한다면 어떤 곳에서 성능적으로 유실이 많은 지 알아내는 것 입니다. \n\n다행히 쿼리 플랜에서 쉽게 병목 구간을 알아낼 수 있습니다. 쿼리 플랜을 보다 보면 `cost` 라는 것이 있다는 것을 알 수 있습니다. 이는 절대적 지표가 아닌, 해당 작업을 수행하는데 상대적인 비용이 얼만큼 들었느냐에 대한 지표입니다. \n\n그럼 가장 `cost` 가 높게 측정되는 구간은 어디일까요?\n\n![](./high-cost-section.png)\n\n해당 작업이 다른 작업들과 `cost` 를 비교했을 때, 가장 높은 `cost` 를 나타내고 있음을 알 수 있습니다. 또한 `cost` 정보 외에도, `actrual time`, `rows` 와 같은 간접적 지표를 통해 작업의 성능을 추측할 수 있습니다.\n\n위 작업에 대해 설명하자면, 기본적인 조건절을 통해 article 데이터를 조회한 결과, 64276개 달하는 데이터를 조회했습니다. 이는 `Seq Scan (Full Scan)` 이기 때문에 Index 를 타지 않고, 조회해온다는 것을 알 수 있습니다.\n\n- `category_id IN ( ?, ? )`\n- `is_deleted = false`\n- `is_blocked = false`\n\n정리하자면 위 조건들이 적용된 쿼리가 Article 테이블을 풀 스캔하여 64276개의 데이터를 조회하게 됩니다. \n그리고 원래 쿼리의 조건절을 다시 보게 되면 위 조건절은 제외하고도 한 가지의 조건절이 더 포함되어 있습니다.\n\n- `( a.user_id = ? OR t.id = ? )`\n\n위 두 조건 모두 피드를 구분 짓는 중요한 조건들입니다. 전자는 `팔로우 한 크리에이터들의 article`을 구분지을 때 사용하는 조건절이고, 후자는 사용자가 등록한 `관심 태그 ID` 가 들어가는 조건입니다. 그리고 이 둘을 모두 포함하도록 `OR 연산자` 가 붙었습니다.\n\n즉 `t.id = ?` 이 구간 때문에 `a.user_id` 로 인덱스를 타려고 하지만 `OR 연산자` 때문에 `t.id = ?` 도 포함하는 Article도 가져와야 하기 때문에 인덱스를 타지 못하고, `Table Full Scan` 을 하게 되어 병목이 발생하게 됩니다.\n\n지금은 `article` 테이블의 전체 데이터 수가 6만여건 밖에 되자 않아, 별로 크게 성능을 저하시키지 않는 것처럼 보이지만, 데이터가 많아지게 되면 치명적입니다.\n>**각각 `category_id` , `is_deleted`, `is_blocked`  인덱스를 생성하면 되지 않을까?**\n>\n> 하지만 해당 인덱스를 생성해도 결과는 똑같습니다. (복합 인덱스라면 이야기가 다를 수 있다.) `PostgreSQL` 은 조회하는 데이터가 해당 테이블의 많은 부분을 차지하면, Index가 아닌 Full-Scan을 통해 데이터를 조회합니다. (카디널리티가 낮으면 인덱스 효과가 떨어지기 때문에)\n\n그럼 쿼리 플랜을 통해 병목 구간을 확인했으니, 개선 방법을 알아봅시다.\n\n### 쿼리 개선\n---\n위 쿼리를 실행하면 약 `67ms` 의  시간이 소요되었습니다. 전혀 길지 않은 실행시간이지만, 더 단축시키게 되면 많은 요청이 몰렸을 때나 데이터가 많아졌을 때, 하나의 \b트랜잭션 자체에 Connection을 물고 있는 시간을 개선 할 수 있습니다.\n\n아직 효율적인 쿼리 작성에 미숙하기에, 가장 빨리 데이터를 조회할 수 있는 방법을 선택했습니다.\n\n우선 해당 쿼리를 인덱스를 타는 방향으로 개선하는게 좋아보였습니다. 현재 쿼리는 너무나 많은 `article` 을 조회하기 때문에 적절한 개수의 `article` 을 조회하도록 개선이 필요했습니다. 즉 `user_id` 에 대한 **인덱스**를 타게끔 유도해야 합니다.\n\n**그래서 쿼리를 분리하기로 결정했습니다.**\n\n`article_tag` 와 `tag` 테이블을 조인하지 않고, `user_id` 처럼 유저가 가지고 있는 관심 태그를 기반한 `article` 의 `id` 를 인자로 받아서 다음과 같은 쿼리로 개선하기로 하였습니다.\n\n```sql\nSELECT a.id\nFROM   article a\nWHERE  ( a.user_id = ? OR a.id = ? )\n       AND ( a.category_id IN ( ?, ? ) )\n       AND a.is_deleted = ?\n       AND a.is_block = ?\nGROUP  BY a.id\nORDER  BY a.id DESC\n```\n\n쿼리가 훨씬 간단해졌습니다. 이런식으로 쿼리를 튜닝하게 되면 `user_id` 와 `id` 가 Index를 타게 되어, 전보다 훨씬 빠른 속도로 데이터를 조회하게 되어, 성능이 향상됩니다. 이 결과 역시 쿼리 플랜을 통해 확인할 수 있습니다.\n\n![](./fix-query-result.png)\n\nOR 연선자에 해당하는 데이터들은 모두 `Index Scan`을 통해 조회했고, 그 후에 기본 조건들을 적용했습니다.\n\n최종적으로 **`기존 67ms` 쿼리 실행 시간에서 0.5ms 로 134배 향상되었음을 확인할 수 있습니다.**\n\n하지만 JOIN을 통해 태그 정보를 가져오는 것이아닌, 인자로 유저의 관심 태그를 보유한 `article.id` 목록을 가져오는 것이기 때문에 발생하는 쿼리가 늘어난다는 단점이 존재합니다. \n\n그럼에도 불구하고 조인을 제거하고, 단일 테이블 조건으로 바꾼 덕분에 쿼리의 속도, 인덱스 효율, 캐시 적중률이 압도적으로 좋아졌고 총 쿼리의 수가 N+1 문제와 같이 치명적인 수준의 쿼리의 개수가 늘어난 것임이 아니기 때문에 적절한 개선 방법이라고 생각합니다.\n\n### 마무리\n---\n결과적으로 의미있는 성능 개선의 경험을 할 수 있었습니다. 위 방법처럼 쿼리 플랜을 통해 쿼리를 분석한다면 성능 개선에 더욱 더 도움이 될 수 있습니다. 하지만 저런식으로 나오는 쿼리 플랜의 결과물은 다소 가독성이 떨어집니다. 그래서 이를 보기 좋게 시각화 해주는 툴을 소개해주도록 하겠습니다.\n\n먼저 분석하고자 하는 쿼리에 다음과 같은 키워드를 추가합니다\n\n```sql\n# 기존\nEXPLAIN ANALYZE\n...SQL\n\n# 변경\nEXPLAIN (ANALYZE, COSTS, VERBOSE, BUFFERS, FORMAT, JSON)\n...SQL\n```\n\n해당 쿼리의 결과물을 https://explain.dalibo.com/ 의 Plan 부분에 붙여넣고 전송하게 되면 쿼리 플랜을 시각화하여 볼 수 있습니다."},{"excerpt":"은  의 고가용성 (High Availabiliity)를 보장하기 위한 시스템입니다. 많은 요청을 처리해야 하는 서비스에서 만약 한 대의 Redis만 사용한다면 과도한 부하로 인해 장애가 발생했을 때, Redis에 의존하는 서비스들은 정상적으로 운영하기 어렵고, 성능이 대폭 감소할 수 있습니다.  고가용성이란?\n고가용성 (HA, High Availabil…","fields":{"slug":"/redis-sentinel/"},"frontmatter":{"date":"June 16, 2025","title":"Redis-Sentinel에 대해 알아보고 직접 구현해보기","tags":["Redis","Redis-Sentinel","분산"]},"rawMarkdownBody":"`Redis Sentinel` 은 `Redis` 의 **고가용성 (High Availabiliity)**를 보장하기 위한 시스템입니다.\n\n많은 요청을 처리해야 하는 서비스에서 만약 한 대의 Redis만 사용한다면 과도한 부하로 인해 장애가 발생했을 때, Redis에 의존하는 서비스들은 정상적으로 운영하기 어렵고, 성능이 대폭 감소할 수 있습니다. \n\n> **고가용성이란?<br>**\n> 고가용성 (HA, High Availability) 란? 쉽게 말해서 어떠한 서버나 시스템이 오랫 동안 정상 운영이 가능한 정도를 이야기 합니다. 장애가 발생하더라도, 이를 빠른 시간 안에 복구하고, 정상적인 서비스를 운영하여 서비스 신뢰성을 복구한다면 고가용성이 높다라고 말할 수 있습니다.\n> \n> 고가용성을 높이는 방법과 전략에는 여러가지가 있지만, 본 포스트에서는 `Redis-Sentinel` 을 중심적으로 설명하겠습니다.\n\n## Redis-Sentinel\n---\nRedis Sentinel 은 앞서 말했듯이 Redis의 고가용성을 보장하기 위한 시스템입니다. 분산 환경에서는 Redis가 여러 노드에 걸쳐 동작됩니다. 모니터링을 통해 `master` 및 `replica` 가 정상적으로 동작하는지 확인하고, 자동으로 장애를 복구할 수 있는 기능을 제공합니다.\n\n보통의 Sentinel은 3개 이상의 인스턴스를 구성합니다. 이렇게 구성하면 합의를 통해 장애 여부를 판단할 수 있어 더욱 더 안정적인 시스템을 구성할 수 있습니다.\n\n### 주요 개념\n---\n**Quorum** <br>\nQuorum(합의) 이란 각각의 Sentinel 들이 master 가 죽었다고 판단할 때 `필요한 최소한의 합의 수` 입니다.\n만약 `Quorum = 3` 이라면, 최소 3개의 Sentinel 이 `master` 가 죽었다고 판단해야 장애 복구가 시작 됩니다.\n\n**Failover** <br>\nFailover 란 시스템에 한 구성 요소에 장애가 발생했을 때, 즉시 다른 예비 시스템으로 대체하여 서비스를 계속해서 지속하는 기능입니다. Redis Sentinel 에서는 master 에 장애가 발생하였을 때, 여러 replica 인스턴스 중 1개를 master를 승격 시키는 것을 의미합니다.\n\n### What is Sentinel?\n---\n1개의 Redis 인스턴스만을 사용한다면, 해당 Redis에 부하가 생겨 장애가 발생했을 때, Redis에 의존하는 서비스들은 정상적으로 운영하기 어렵고, 성능이 대폭 감소할 우려가 있습니다. \n\n![Redis Master-Replica](redis-master-slave.png)\n\n이를 해결하기 `Master-Replica` 구조로 Redis 환경을 구성하는데요, 이는 `Master Redis Instance` 를 통해 데이터를 쓰고, 다수의 `Replica Redis 인스턴스`에서 데이터를 읽는 구조인 것 입니다. 상대적으로 읽기 처리를 해야 하는 서비스가 많기 때문에 읽기 전용 `Replica Redis 인스턴스` 를 늘리는 구조입니다.\n\n데이터가 여러 인스턴스에 복제되어 있어, 읽기 요청 처리를 분산 시킬 수 있어 부하를 줄일 수 있다는 장점이 있습니다.\n\n그런데 만약 이러한 구조에서 `Master Redis Instance` 에 문제가 생기면 어떻게 될까요?\n\n![](net-connected.png)\n\nApplication 운영 도중 `Master Redis Instance` 에 장에가 발생하면 위와 같이 Connection 끊깁니다.\n\n![](reconnecting.png)\n\n이후, `Master Redis Instance` 가 정상적으로 동적하게 되면 재연결하여 이전처럼 정상적으로 Redis를 사용할 수 있게됩니다. \n\n하지만 이렇게 `Master Redis Instance` 에 장애가 생기면 사람이 직접 장애를 복구해야 하고, 이로 인해 긴 시간 동안 Redis를 사용 하지 못하면서 DB에 부하가 생겨 **전체 시스템에 장애가 전파될 수도 있습니다. **\n\n![Master Redis Instance에 장애가 발생한 상황](problem-ocurred.png)\n\n하지만 여전히 `Replica` 는 정상적으로 운영이 가능합니다. `Redis-Sentinel` 은 바로 이 여분의 Replica를 Master로 승격시켜, 장애를 복구하는 시스템을 의미합니다. \n\n하지만 `Master Redis Instance` 에 장애가 발생했다고 어떻게 판단할까요? 그것을 판단하는 것이 바로 `Sentinel` 이란 존재입니다.\n\n\n### Sentinel의 역할\n---\n- `모니터링`\n- `자동 장애 조치`\n- `알림`\n\n`Sentinel` 은 대략적으로 위와 같은 역할을 합니다. \n\n`Master Instance`와 `Replica Instance` 를 주기적으로 모니터링하여 장애가 발생했는지 확인합니다. \n\n이에 `Master Redis Instance` 가 응답하지 않으면 `주관적 다운` 상태로 판단합니다. \n또한 `Master Redis Instance` 가 여러 `Sentinel` 등에 다운됐다고 판단되면 `Quorum` 을 통해 `객관적 다운` 상태로 판단하여, 여러 `Replica` 중 하나를 `Master` 로 승격합니다. \n\n그리고 나머지 `Replica` 들은 새롭게 승격된 `Master` 를 바라보게 만듭니다. 이 외에도 장애 및 복구와 같은 이벤트가 있을 때, 사용자가 설정한 것을 토대로 알림을 전송해주기도 합니다.\n\n### 몇 대의 Sentinel이 필요할까?\n앞서, `Sentinel` 은 여러 `Sentinel` 들에 의해 `Master` 가 다운된 것을 합의한다고 했습니다. \n하지만 `단일 Sentinel` 을 운용하고 만약 그 `Sentinel` 에 네트워크 문제가 발생했다면\n이를 `Master`의 주관적 다운이라고 판단하고 이는 `단일 Sentinel` 이기 때문에 객관적 다운으로 이어집니다. \n\n그렇게 되면 실제로 장애가 발생하지 않았는데도, `Replica`를 `Master`로 승격시켜버리는 문제가 발생합니다. 이에 Sentinel 은 `최소 3대` 가 존재해야 이를 객관적으로 `Master` 가 다운됐다고 판단할 수 있기에 과반이 형성될 수 있는 `최소 3대의 Sentinel` 을 운용해야 효과적으로 자동 장애 복구 및 감지 기능을 발휘할 수 있습니다.\n\n![redis-sentinel의 대략적인 구조](redis-sentinel.png)\n## 구현해보기\n\n간단하게 Docker를 통해 구현해보도록 하겠습니다. 총 6개의 컨테이너의 분류는 다음과 같습니다.\n\n- `redis-master`\n- `redis-replica-1`\n- `redis-replica-2`\n- `redis-sentinel-1`\n- `redis-sentinel-2`\n- `redis-sentinel-3`\n\n먼저 `redis-master` 를 올려주도록 하겠습니다.\n\n```shell\ndocker run -d --name redis-master --network {NETWORK_NAME} -p {PORT}:6379 redis:{TAG} redis-server --apendonly yes\n```\n\n- `--appendonly` : 데이터를 영구적으로 저장하기 위한 옵션입니다. `appendonly.aof` 파일에 기록하고 서버 재시작 시 해당 내용을 기반으로 데이터를 복원합니다.\n\n다음은 `redis-replica-n` 입니다.\n\n```shell\ndocker run -d --name redis-replica-n --network {NETWORK_NAME} -p {PORT}:6379 redis:latest redis-server --slaveof redis-master 6379\n```\n\n- `--slaveof` : 호스트가 `redis-master` 이고 포트가 `6379` 인 마스터를 따른다는 옵션입니다. 즉 해당 Master의 Replica로 설정됩니다.\n\n원하는 개수의 `Replica` 만큼 생성하면 됩니다.\n\n이제 마지막으로 `redis-sentinel`을 생성할 차례입니다.\n\n```shell\ndocker run -d \\\n--name sentinel-1 \\\n--network {NETWORK_NAME} \\\n-p {PORT}:26379 \\\n-v $(pwd)/sentinel.conf:/etc/sentinel/sentinel.conf \\\nredis:latest \\\nsh -c \"sleep 5 && redis-sentinel /etc/sentinel/sentinel.conf\"\n```\n\nSentinel의 경우 옵션을 넣는 파일을 Volume을 잡았다. 이에 `sentinel.conf` 내용은 다음과 같습니다.\n\n```conf\nsentinel monitor mymaster {MASTER_IP} 6379 2\nsentinel down-after-milliseconds mymaster 5000\nsentinel failover-timeout mymaster 10000\n# sentinel auth-pass mymaster {MASTER_PASS}\n```\n\n- `monitor mymaster redis-master 6379 2` : 내부에서 mymaster 라는 이름으로 redis-master:6379 라는 master를 모니터링 하고, `최소 2개의 Sentinel` 이 `Master` 가 다운되었다고 판단해야 `Failover` 를 수행한다는 설정입니다.\n- `down-after-milliseconds mymaster 5000` : Master가 5(5000ms)초 동안 응답이 없으면 다운된 것으로 판단합니다. (주관적 판단)\n- `failover-timeout mymaster 10000` : Failover 시 전체 프로세스에 적용될 Timeout의 설정값 (새 마스터 승격, 클러스터 재구성 등등)\n- `auth-pass mymaster {PASSWORD}` : Master 생성 시 `Pass`를 설정했다면 기록되는 값\n\n위 과정을 따랐다면, 총 `6개의 컨테이너`가 성공적으로 동작할 것 입니다.. 이제 Master가 다운되었을 때, 각각의 Sentinel 들이 합의를 통해 Replica 중 하나를 Master로 승격하는지 확인하는 과정이 남았습니다.\n\n## 확인하기\n\n먼저 `redis-master` 와 `redis-replica-n` 잘 연결되어있는지 확인해봅니다.\n\n```shell\ndocker exec -it redis-master redis-cli info replication\n```\n\n![redis-master 컨테이너의 Replication 정보](replication-result.png)\n\n해당 명령어를 통해 `Master Redis Instance` 와 연결된 `Replication Redis Instance` 들의 정보를 확인할 수 있습니다.\n\n그리고 Sentinel 목록 중 하나의 컨테이너에서 마스터를 잘 바라보고 있는지 확인합니다.\n\n```shell\ndocker exec -it sentinel-n redis-cli -p {PORT} sentinel get-master-addr-by-name {MASTER_NAME}\n```\n\n![결과로 Master Redis Instance의 IP 주소가 나온다.](get-master-addr-by-name-result.png)\n\n 이제 Master를 다운 시켜서 각각의 Sentinel 들의 합의를 통해 Replica 중 하나를 Master 로 승격시키는 지 확인해봅시다. `Master` 를 다운 시키기 위해서 `redis-master` 컨테이너를 정지 시켜 봅시다.\n\n```shell\ndocker stop redis-master\n```\n\n그리고 여러 `Sentinel 컨테이너` 중 하나의 로그를 살펴봅니다.\n\n```shell\ndocker logs -f sentinel-1\n```\n\n```\n10:X 16 Jun 2025 06:52:14.841 # +vote-for-leader c193c15f0a95f7b655f6ab0225f0042a958d11e1 1\n10:X 16 Jun 2025 06:52:15.785 # +odown master mymaster 172.18.0.2 6379 #quorum 3/2\n10:X 16 Jun 2025 06:52:15.785 * Next failover delay: I will not start a failover before Mon Jun 16 06:52:35 2025\n10:X 16 Jun 2025 06:52:16.014 # +config-update-from sentinel c193c15f0a95f7b655f6ab0225f0042a958d11e1 172.18.0.5 26379 @ mymaster 172.18.0.2 6379\n10:X 16 Jun 2025 06:52:16.014 # +switch-master mymaster 172.18.0.2 6379 172.18.0.4 6379\n```\n\n`redis-master` 컨테이너를 중지시키게 되면, 각각의 `Sentinel` 이 투표를 통해 `redis-master` 가 다운됐다는 것을 공식적으로 확인합니다. 그리고 투표의 값이 우리가 [설정한 임계값]() 을 넘어가게 되면, (로그에서는 3/2로 과반을 넘었다.) `Replica Redis Instance` 중 하나를 `Master Redis Instance` 로 승격시킵니다.\n\n\n승격이 완료된 뒤에 `Sentinel` 에서 다음 명령어를 통해 바라보고 있는 Master 를 확인할 수 있습니다.\n\n```shell\nredis-cli > SENTINEL get-master-addr-by-name {모니터링_하고_있는_Master_이름}\n```\n\n다음과 같이 다른 `Replica Redis Instance` 의 주소가 저장되어 있는 것을 확인할 수 있습니다.\n\n![새롭게 승격된 Master Redis Instance의 구조](new-structure.png)\n\n정확히 확인하기 위해서, 새롭게 승격된 `Master Redis Instance` 에 접속하여 `info replication` 명령어를 확인하면 `role:master` 임을 확인할 수 있습니다.\n\n![](after-master-down-sentinel-master-addr.png)\n\n그리고 이전에 중지된 `redis-master` 를 정상적으로 복구 시키게 되면 현재 `Master Redis Instance` 의 `Replica`로 붙게 됩니다.\n\n자세한 코드 내용은 [블로그 코드 저장소](https://github.com/jin-daram/tech-blog-code-lab) 에서 내용을 확인하실 수 있습니다.\n\n## 마무리\n\n이렇게 `Redis Sentinel` 에 대해 알아보고, 직접 테스트하여 `Quorum`, `Failover` 의 처리를 눈으로 확인해보았습니다. 학습하면서 알게 된 사실인데, Master-Replica 구조로 Redis를 구성했을 때, 읽기 요청 시 자동으로 로드밸런싱을 해주는 것이 아니더군요. *( `Lettuce`와 같은 Redis Client 에서도 지원을 안하는 것 같았습니다. )*\n\n\n그래서 [Twemproxy](https://github.com/twitter/twemproxy) 나 [Predixy](https://github.com/joyieldInc/predixy) 와 같은 프록시를 거쳐야 한다는 것을 알았습니다. [참조](https://github.com/redis/lettuce/issues/834) \n\n> Lettuce selects a slave per slot hash and uses the selected slave for read operations until the next topology refresh. This is by design to reduce CPU overhead.\n\n이를 통해 Redis의 구성이 변경되지 않는 한 *(e.g 새로운 Replica Redis가 추가된다거나 등)* 지정된 Replica에 대해서만 읽기 요청을 보낸다는 것 같았습니다.\n\n사실 이러한 설정은 굉장히 복잡하고, 네트워크도 설정해야 하니, 수지타산을 고려하여 이런 것들을 상대적으로 쉽게 설정할 수 있는 `AWS ElastiCache` 와 같은 서비스를 이용하는 것도 좋을 것 같습니다.\n"},{"excerpt":"이전 글 (NestJS 트랜잭션 적용 원리 알아보기) 에서는 NestJS와 Node.js 환경에서 TypeORM을 통해 어떤식으로  을 적용할 수 있는지 실제  코드와 함께 살펴봤다. 본 포스트에서는 typeorm-transactional을 사용하지 않고, 직접  Decorator를 구현하여 간편하게 트랜잭션을 적용하는 법을 보이겠다. Node.js의 T…","fields":{"slug":"/nestjs-tx-implement/"},"frontmatter":{"date":"June 12, 2025","title":"NestJS @Transactional 구현하기","tags":["Node.js","NestJS","트랜잭션","TypeORM"]},"rawMarkdownBody":"\n[이전 글 (NestJS 트랜잭션 적용 원리 알아보기)]() 에서는 NestJS와 Node.js 환경에서 TypeORM을 통해 어떤식으로 `Transaction` 을 적용할 수 있는지 실제 `TypeORM` 코드와 함께 살펴봤다.\n\n본 포스트에서는 [typeorm-transactional](https://www.npmjs.com/package/typeorm-transactional)을 사용하지 않고, 직접 `@Transactional` Decorator를 구현하여 간편하게 트랜잭션을 적용하는 법을 보이겠다.\n\n\n## Node.js의 Thread Local Storage\n\nThread Local Storage는 쉽게 말해서 각 Thread 마다 따로 저장되는 값이다. 멀티 스레드 환경에서 데이터 충돌을 방지하는 목적으로 사용하는 데 유용하다. \n\n```java\n/* Java에서 ThreadLocalStorage를 생성하고 사용하기 */\nThreadLocal<String> threadLocal = new ThreadLocal<>();\n\nthreadLocal.set(\"A\");\nString value = threadLocal.get(); // return \"A\"\n```\n\n다른 스레드에서는 `threadLocal` 변수에 저장된 `\"A\"` 라는 값을 조회할 수 없다.\n\n`Spring Boot`는 `멀티 스레드` 환경이기에 `ThreadPool` 에서 요청 하나 당 1개의 Thread를 할당 받아 처리하기 때문에 `ThreadLocal` 클래스를 통해 `ThreadLocalStorage` 를 사용할 수 있다.\n\n하지만 `Node.js` 환경은 `싱글 스레드 기반` 으로 동작하기 때문에 요청별 컨텍스트를 분리할 수 없어 기본적으로 Thread Local Storage를 만들 수 없다.\n\n### cls-hooked\n[cls-hooked](https://www.npmjs.com/package/cls-hooked) 는 `Node.js` 에서 `ThreadLocal` 처럼 동작하는 `Continuation-Local-Storage` 를 만들기 위해 나온 모듈이다. 이는 내부 `Namespace` 를 하나 생성하여, 내부적으로 `Map<asyncId, Context>` 구조로 저장소를 갖는다. \n\n하지만 마지막 업데이트가 너무 오래전이고, 비공식 구현체이다.\n\n\n### Async Local Storage\n`async_hooks` 기반으로 동작되는 공식 `Node.js` 의 `Async Local Storage` 이다. \n\n> **async_hooks 란?**\n> `async_hooks` 는 `Node.js` 에서 제공하는 비동기 콜백의 생명주기를 추적할 수 있는 API 이다. 싱글 스레드 기반인 Node.js 에서는 비동기 함수들의 흐름이 섞일 경우, 이를 추적하기 어렵다. 이를 쉽게하기 위해서 구현된 것이 `async_hooks` 이다.\n> 다만 이 `async_hook` 는 사용이 금지시 되고 있다. 비동기 컨텍스트 추적 용도로는 `AsyncLocalStorage` 를 사용하도록 권고되고 있다. [참고](https://nodejs.org/api/async_hooks.html?utm_source=chatgpt.com#async-hooks)\n\n`AsyncLocalStorage` 는 비동기 컨텍스트 유지가 가능하고, Node.js 에서 공식적으로 지원하는 비동기 컨텍스트 추적 객체이다. 다음과 같이 사용할 수 있다.\n\n```ts\n/* async-context.ts */\nimport { AsyncLocalStorage } from 'node:async_hooks';\n\nconst asyncLocalStorage = new AsyncLocalStorage<string>();\n\nexport const context = {\n  run: (value: string, callback: () => void) => {\n    asyncLocalStorage.run(value, callback);\n  },\n  get: (): string | undefined => {\n    return asyncLocalStorage.getStore();\n  },\n};\n```\n\n```ts\n/* runner.ts */\nimport { context } from './async-context';\n\ncontext.run('hello jin-daram', () => {\n  setTimeout(() => {\n    console.log(context.get());\n  }, 100);\n});\n```\n\n`Node.js` 기반 서버와 응용하여 사용하면 `Spring Boot` 의 `ThreadLocal` 처럼 활용할 수 있다.\n\n \n## @Transactional\n\n위에서, 알게 된 내용을 바탕으로 `@Transactional` Decorator를 생성하여 본다. 먼저 트랜잭션이 필요한 `Post` 요청을 처리하는 `Service`를 생성하도록 한다.\n\n```ts\n@Injectable()\nexport class UserService {\n\n  async createUser(userCreateRequest: UserCreateRequest): Promise<void> {\n    await this.userRepository.save(userCreateRequest);\n  }\n\n}\n```\n\n요청 정보로 `User` 를 생성하는 매우 간단한 코드이다. 지금은 `UserRepository` 생성 시 선언된 `EntityManager`를 통해 트랜잭션을 유지하기 때문에 `createUser()` 함수에 다른 엔티티에 대한 `INSERT`, `UPDATE`, `DELETE` 쿼리가 추가된다면 트랜잭션이 유지될 수 없는 상황이다.\n\n이제 `createUser()` 함수가 실행되기 전에 `em.transaction()` 콜백 함수의 인자로 들어오는 manager를 해당 요청 내에서 사용해야한다. 즉 `UserRepository` 에서 접근하는 `EntityManager` 가 변경되어야 하고, 이 접근 방식을 다르게 설정해야 한다. \n\n이는 `typeorm-transactional` 에서 구현했던 방식과 비슷하게 `Object.defineProperty(...)` 함수를 이용해서 설정한다.\n\n```ts\n/* init.ts */\nexport function init() {\n    Object.defineProperty(Repository.prototype, 'manager', {\n        configurable: true,\n        get() {\n            return context.get('entityManager')\n        },\n        set() {\n\n        }\n    })\n}\n```\n\n우리는 `CustomRepository` 를 만들 때, 반드시 `Repository<Entity extends ObjectLiteral>` 를 상속받아 사용한다. `Repository`의 `prototype`의 `manager` 라는 속성에 접근할 때, `Repository.manager` 에 접근하는 것이 아닌, 우리가 나중에 생성할 `Request Context` 에서 접근하도록 설정한다.\n\n```ts\n/* user.repository.ts */\nexport class UserRepository extends Repository<User> {\n  ...\n}\n```\n\n그리고 해당 함수를 `main.ts` 에서 App이 실행되기 전에 싫맹한다.\n```ts\n/* main.ts */\n\ninit()\n...\nbootstrap();\n\n```\n\n### Context 만들기\n`cls-hooked` 는 오래 전에 업데이트 되었기 때문에 상대적으로 최근에 생기고, `Node.js` 에서 지원하는 `Async-Local-Storage` 를 전격 활용하여 개발하도록 한다.\n\n```ts\n/* context.ts */\nexport class Context {\n\n    private dataSource: DataSource;\n    private readonly asyncLocalStorage = new AsyncLocalStorage<Map<string,EntityManager>>();\n\n    public getDataSource() {\n        return this.dataSource;\n    }\n\n    public async setDataSource(targetDataSource: DataSource) {\n        await targetDataSource.initialize();\n        this.dataSource = targetDataSource;\n    }\n\n    public run(store: Map<string, any>, callback: () => Promise<any>) {\n        return this.asyncLocalStorage.run(store, callback);\n    }\n\n    public get(key: string) {\n        return this.asyncLocalStorage.getStore()?.get(key);\n    }\n\n}\n```\n\n먼저 간단한 `Context` 클래스를 생성한다. 내부에는 `DataSource` 와 `AsyncLocalStorage` 로 이루어져 있다.\n \nDataSource는 `@Transactional` Decorator 에서 트랜잭션를 생성하기 위해 저장한다. 그렇기 때문에 `main.ts`에서 해당 `Context` 에 `DataSource` Mapping이 필요하다.\n\n```ts\ncontext.setDataSource(new DataSource({\n  type : \"postgres\",\n  host : \"localhost\",\n  port : 5433,\n  username: \"postgres\",\n  password : \"mypassword\",\n  database: \"postgres\",\n  entities: [User],\n  logging: true,\n}))\n\ninit()\n...\nbootstrap();\n```\n\n지금은 수동으로 `DataSource` 를 지정해주었지만, 향후 `TypeORM` 모듈을 통해 `Context` 에 자동으로 `DataSource` 를 설정하는 것도 가능할 것 같다.\n\n### @Transactional Decorator 생성하기\n```ts\nexport function Transactional(): MethodDecorator {\n  return function (_target, _propertyKey, descriptor: PropertyDescriptor) {\n    const original = descriptor.value;\n\n    descriptor.value = async function (...args: any[]) {\n      const dataSource = context.getDataSource();\n      return await dataSource.manager.transaction(async (transactionManager) => {\n        return await context.run(new Map([['entityManager', transactionManager]]), async () => {\n          return await original.apply(this, args);\n        });\n      });\n    };\n  };\n}\n```\n\n코드 구성은 간단하다. 전역적으로 접근할 수 있는 Context 로 부터, DataSource를 가져온다.\n\n그런 후에 DataSource의 EntityManager의 transaction() 함수를 통해 콜백 함수의 인자로 주어진 EntityManager를 `Map<string, EntityManager>` 형태의 Store에 저장한다.\n\n그리고 실행하고자 하는 함수를 실행한다.\n\n### 적용하기\n\n기존에 트랜잭션을 적용하고자 했던 함수에 `@Transactional` Decorator를 붙인다.\n\n```ts\n@Injectable()\nexport class UserService {\n\n  @Transactional\n  async createUser(userCreateRequest: UserCreateRequest): Promise<void> {\n    await this.userRepository.save(userCreateRequest);\n  }\n\n}\n```\n\n이후 결과를 확인해보면 성공적으로 트랜잭션이 원하는 대로 적용되는 것을 확인할 수 있다.\n\n![Transaction이 정상적으로 적용되는 모습](./transaction-success.png)\n\n\n### 문제점\n\n하지만 여전히 부족한 점이 많다. 트랜잭션이 정상적으로 적용되기는 하지만, 로직이 복잡해지고, 함수가 분리되는 경우의 트랜잭션 전략에 대한 전략책이 없다. `typeorm-transactional` 에서는 이런 것 까지 잘 지원하고 있으니, 결국 좋은 라이브러리를 사용하는 것이 좋은 것 같다.\n\n본 포스트는 `DataSource`, `EntityManger` 와 관련하여 `TypeORM` 환경에서 `Transaction` 이 어떻게 적용되는지에 대한 학습을 목적으로 작성한 글이기 때문에 부족한 부분이 있을 수 있다. 피드백은 언제나 환영이기에 하단의 **Discussion** 을 적극적으로 활용해주시기 바란다.\n\n자세한 코드는 [블로그 코드 Repository](https://github.com/jin-daram/tech-blog-code-lab) 에서 확인 할 수 있다.\n"},{"excerpt":"Spring Boot 에서는 다음과 같은 코드로 간단하게  을 적용할 수 있다.  자세한 적용 원리나 옵션에 대해서는 의 @Transactional Annotation에 대해 학습이 필용하지만, 위 방법으로 단순하고 간단하게 을 적용할 수 있다. 이것이 가능하게 하는 것이 바로 AOP (Aspect-Oriented Programming, 관점 지향 프로그…","fields":{"slug":"/nestjs-tx-principle/"},"frontmatter":{"date":"June 05, 2025","title":"NestJS 트랜잭션 적용 원리 알아보기","tags":["Node.js","NestJS","트랜잭션","TypeORM"]},"rawMarkdownBody":"\n**Spring Boot** 에서는 다음과 같은 코드로 간단하게 `트랜잭션` 을 적용할 수 있다. \n\n```java\npublic class UserService {\n\n    private final UserRepository userRepository;\n    \n    @Transactional // 트랜잭션 적용\n    public void createUser(UserCreateRequest request) {\n        User user = userRepository.save(new User(...));\n    }\n}\n```\n\n자세한 적용 원리나 옵션에 대해서는 `Spring Boot`의 [@Transactional](https://docs.spring.io/spring-framework/reference/data-access/transaction/declarative/annotations.html) Annotation에 대해 학습이 필용하지만, 위 방법으로 단순하고 간단하게 `트랜잭션`을 적용할 수 있다.\n\n이것이 가능하게 하는 것이 바로 **AOP (Aspect-Oriented Programming, 관점 지향 프로그래밍, 이하 AOP)** 이다.\n\n## AOP?\n---\n> AOP 설명을 목적으로 하는 포스트는 아니기 때문에 단순하게 설명함으로 양해 부탁드립니다. 자세한 이론적인 내용은 [위키백과 - AOP](https://ko.wikipedia.org/wiki/%EA%B4%80%EC%A0%90_%EC%A7%80%ED%96%A5_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D) 를 참고 하길 바랍니다.\n\n쉽게 말하자면 `비즈니스 로직은  건들지 않고, 공통적으로 해야 하는 일을 앞, 뒤로 끼워넣는 프로그래밍 기법` 이다.\n<br>\n\n만약 프로젝트 내 모든 메소드의 실행 시간을 기록해야 한다면 어떨까?\n\n```java\npublic void login() {\n\tlong startTime = System.currentMillis();\n\t// 비즈니스 로직\n\tlog endTime = System.currentMillis();\n\tSystem.out.println(endTime - startTime + \"ms\")\n}\n```\n\n위 코드와 같은 포맷이 모든 메소드에 추가 되어야 할 것이다. 하지만 다음과 같이 구현한다면?\n\n```java\n@Measure\npublic void login() {\n\t// 비즈니스 로직\n}\n```\n\n단순히 `@Measure` 을 붙이는 것만으로 해결할 수 있다면 우리는 비즈니스 로직 앞 뒤에 아무것도 붙이지 않고, 깨끗하게 비즈니스 로직에만 집중 할 수 있다. 사실 메소드 소요 시간 측정은 정말 가벼운 기능이 추가되는 것이지만, 더 복잡한 로직이 생기게 된다면, 비즈니스 로직보다 공통 로직이 더 많은 부분을 차지하는 기이한 현상이 벌어질 수 있다.\n\n그렇기 때문에 Spring Boot 환경에서는 `@Transactional` Annotation을 통해 간단하게 `트랜잭션` 을 적용할 수 있는 방법을 제공한다.\n\n## Node.js 환경에서의 트랜잭션\n---\n트랜잭션은 Node.js 환경에서도 물론 필요하다. 그렇기 때문에 적용할 수 있어야 한다. 하지만 관심을 가지지 않으면 단독적으로 트랜잭션이 적용될 수 있다.\n\n```ts\n@Injectable()\nexport class UserService {\n\n\tconstructor(\n\t\tprivate readonly userRepository: UsreRepository,\n\t\tprivate readonly UserDetailRepository: UserDetailRepositoty\n\t)\t{}\n\n\tcreateUser(request: UserCreateRequest) {\n\t\tconst user = this.userRepository.save(request);\n\t\tconst userDetail = this.userDetailRepository.save(request);\n\t}\n\n}\n```\n\n우리의 기대와 달리, 트랜잭션이 `userRepository.save()` 와 `userDetailRepository.save()` 에 각각 적용된다.\n어느 하나라도 실패가 된다면, 다른 쿼리도 `Rollback`  이 되어야 하지만, 실패해도 롤백이 이루어지지 않는다.\n\n![개별적으로 트랜잭션이 적용되는 모습](double-tx-image.png)\n\nTypeORM 설정에서 `logging` 옵션을 `true` 로 두고 `데이터베이스 로그` 를 확인해보면 트랜잭션이 각각 분리되어 전송되는 것을 확인할 수 있다. \n\n만약 둘 중 하나가 실패한다면? 정상적으로 롤백이 이루어질까? 일부러 둘 중 하나의 로직이 실패하게 유도하고 결과를 지켜보자.\n\n![User 테이블은 데이터 저장, UserDetail 테이블은 Rollback](./no-rollback-result.png)\n\n예상했던 결과처럼 `User` 테이블에는 데이터가 성공적으로 삽입되었고, 에러가 발생한 `UserDetail` 데이터는 삽입되지 않았다.\n\n## 트랜잭션 적용하기\n---\n지금까지 트랜잭션이 정상적으로 적용되지 않는다는 것을 알 수 있었다. 이제 NestJS과 TypeORM에서 지원하는 트랜잭션 적용 방법을 알아보도록 하겠다.\n\n```typescript\n@Injectable()\nexport class UserService {\n\tconstructor(private dataSource: DataSource) {}\n\n\tasync createUser(request: UserCreateRequest) {\n\t\tconst queryRunner = this.dataSource.createQueryRunner();\n\t\n\t\tawait queryRunner.connect();\n\t\tawait queryRunner.startTransaction(); // TRANSACTION START\n\n\t\ttry {\n\t\t\tconst user = queryRunner.manager.create(User, request);\n\t\t\tawait queryRunner.manager.save(user); // User 저장\n\t\t\t\n\t\t\tconst detail = queryRunner.manager.create(UserDetail, request);\n\t\t\tawait queryRunner.manager.save(detail); // UserDetail 저장\n\t\t\t\n\t\t\tawait queryRunner.commitTransaction(); // COMMIT\n\t\t} catch (err) {\n\t\t\tawait queryRunner.rollbackTransaction();\n      throw err;\n\t\t} finally {\n\t\t\tawait queryRunner.release();\n\t\t}\n\t\t\n\t}\n}\n```\n\n**심히 당황스럽다.**\n\n핵심 로직은 엔티티를 생성하고, 저장하는 `4줄` 밖에 되지 않는다. 하지만 트랜잭션 로직 때문에 간단한 `createUser()` 함수가 거대해졌다. 혹시라도 함수의 내용이 방대해지거나, 분리가 필요하면 트랜잭션의 추적도 쉽지 않을 것이다.\n\n> **DataSource를 의존성 주입을 받을 수 있는 이유**\n>\n> `@nestjs/typeorm` 의존성을 통해 `TypeOrmModule` 을 import 하면 내부에서 `DataSource` , `EntityManager` 등을 기본적으로 `Provider`로 추가한다. \n> <br> 실제 코드는 [@nestjs/typeorm typeorm-core-module.ts](https://github.com/nestjs/typeorm/blob/master/lib/typeorm-core.module.ts) 에서 확인할 수 있다.\n\n그럼 다음과 같은 코드는 작동하지 않을까? \n\n```ts\n@Injectable()\nexport class UserService {\n\n    constructor(\n        private readonly em: EntityManager,\n        private readonly userRepository: UserRepository,\n    ) {}\n\n    async createUser(userCreateRequest: UserCreateRequest): Promise<void> {\n        await this.em.transaction(async (manager) => {\n            await this.userRepository.save(userCreateRequest);\n        })\n    }\n\n}\n```\n\n![트랜잭션이 중첩되는 모습](nested-tx-image.png)\n\n\n결과는 기대했던 결과와는 달리 `트랜잭션`이 중첩되어 실행된다.\n\n결론부터 말하자면, `UserService의 EntityManager` 와 `UserRepository의 EntityManager`가 서로 다른 참조를 하고 있다는 것이다.  \n\n`UserService` 에 주입된 `EntityManager`의 `transaction`을 통해 생성된 `EntityManager` 와 `UserRepository` 에서 참조하는 `EntityManager` 는 같지 않다. \n\n이는 [TypeORM 공식 Github]() 코드를 통해 확인 할 수 있다.\n\n```ts\n/* typeorm/src/entity-manager/EntityManager.ts  */\n\nasync transaction<T>(...) {\n\t// 만약 해당 클래스에 QueryRunner가 이미 할당되어있다면, EntityManager가\n\t// 이미 Single Connection을 생성한 것 입니다.\n\t// 만약 정의되지 않은 경우, 모든 작업을 실행할 새로운 Single Connection을 생성합니다.\n\tconst queryRunner =\n\t\tthis.queryRunner || this.connection.createQueryRunner()\n}\n```\n\n이 코드는 공식 `TypeORM`의 `EntityManager.ts` 의 코드 중 `transaction()` 함수 중 일부를 발췌한 것이다. 해당 코드는 쿼리 시에 사용할 `QueryRunner` 를 정의하는데, 이미 사용하고 있는 `QueryRunner` 가 없다면 새로운 `QueryRunner` 를 생성한다. \n\n`this.connection.createQueryRunner()` 함수를 통해 새로운 `QueryRunner` 를 생성하게 되는데 이는 `DataSource.ts` 의 `createQueryRunner()` 와 같다.\n\n```typescript\n/* typeorm/src/data-source/DataSource.ts */\n\ncreateQueryRunner(mode: ReplicationMode = \"master\"): QueryRunner {\n\tconst queryRunner = this.driver.createQueryRunner(mode)\n\tconst manager = this.createEntityManager(queryRunner)\n\tObject.assign(queryRunner, { manager: manager })\n\treturn queryRunner\n}\n\ncreateEntityManager(queryRunner?: QueryRunner): EntityManager {\n\treturn new EntityManagerFactory().create(this, queryRunner)\n}\n\n...\n```\n\n실질적인 `QueryRunner` 는 각 `Database Driver` 를 구현한 구현체에 맡기고, `EntityManager` 는 `DataSource.ts` 에 정의된 `createEntityManager()` 함수를 통해 생성하여, `QueryRunner` 의 `manager` 에 저장한다. \n\n그렇기 때문에 `UserService` 에 주입된 `EntityManager` 와 `UserRepository에서` 참조하는 `EntityManager` 가 서로 다른 객체를 참조하고 있는 것이다.\n\n그럼 어떻게 `EntityManager.transaction()` 의 인자로 주어진 함수에서 같은 `EntityManager` 를 사용할 수 있을까? \n\n이 내용은 앞서 이야기 했던 `AOP` 라는 주제와 함꼐 직접 `@Transactional` 을 구현하여, 적용해보는 내용을 [다음 글]() 에 소개하도록 하겠다."},{"excerpt":"어느 날, 마우스 휠 Up, Down을 통해 IntelliJ Editor의 Font Size 조절이 갑자기 되지 않았다.  옵션을 건드려봐도, Mac 자체에서 지원하는 Zoom이 될 뿐, Editor의 Font Size가 변경되지는 않았다. 해결방법 1. 손쉬운 사용 설정 켜져있는지 확인 나의 경우  에서  에 가 매핑되어 있었다.  이러한 경우  옵션을…","fields":{"slug":"/intellij-zoom-issue/"},"frontmatter":{"date":"May 15, 2025","title":"IntelliJ Mouse Wheel Zoom 이슈","tags":["이슈","개발환경"]},"rawMarkdownBody":"어느 날, 마우스 휠 Up, Down을 통해 IntelliJ Editor의 Font Size 조절이 갑자기 되지 않았다.\n\n`IntelliJ IDEA -> Settings -> Editor -> General -> Change font size in Command + Mouse Wheel in` 옵션을 건드려봐도, Mac 자체에서 지원하는 Zoom이 될 뿐, Editor의 Font Size가 변경되지는 않았다.\n## 해결방법\n### 1. 손쉬운 사용 설정 켜져있는지 확인\n나의 경우 `손쉬운 사용 -> 확대/축소` 에서 `스크롤 제스처를 위한 보조 키` 에 `Command(⌘)`가 매핑되어 있었다.\n\n![스크롤 제스처를 위한 보조 키에 Command(⌘)가 설정되어 있다.](image.png)\n\n이러한 경우 `스크롤 제스처를 위한 보조 키` 옵션을 다른 키로 설정하여 주고, IntelliJ의 `IntelliJ IDEA -> Settings -> Editor -> General -> Change font size in Command + Mouse Wheel in` 옵션이 켜져있으면 정상적으로 마우스 휠을 통해 Font Size 조절이 가능하다.\n\n### 2. Keymap\n`스크롤 제스처를 위한 보조 키` 옵션을 변경하지 않고 해결하는 방법은 바로 IntelliJ의 `Keymap`을 활용하는 것이다. \n\n1. `IntelliJ IDEA` -> `Settings` -> `Keymap`\n2. `Increase Font Size` 검색 <br>\n  a. `Add ... Shortcut` 선택 후 단축키 입력\n3. `Decrease Font Size` 검색 <br>\n  a. `Add ... Shortcut` 선택 후 단축키 입력\n\n![Keymap - Increase Font Size 검색 화면](image-1.png)\n\n해당 설정은 `스크롤 제스처를 위한 보조 키` 옵션에 `Command(⌘)`가 설정되어 있고, 바꾸고 싶지 않을 때 사용할 수 있는 설정이다. 단축키 설정 시, `Command(⌘)`가 들어가지 않게 설정하여야 유효하게 사용할 수 있다."}]}},"pageContext":{}},"staticQueryHashes":[],"slicesMap":{}}